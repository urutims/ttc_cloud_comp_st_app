import streamlit as st
from huggingface_hub import InferenceClient
from huggingface_hub.utils import RepositoryNotFoundError, HfHubHTTPError

MODEL = "google/gemma-2-2b-it"
API_TOKEN = st.secrets["hugging_face_token"]
client = InferenceClient(model=MODEL, token=API_TOKEN)

system_message_init = """ã‚ãªãŸã¯é›·ã§æ€–ãŒã£ã¦ã„ã‚‹ä¿è‚²åœ’ã«ã„ã‚‹å­ä¾›ã€ç”°ä¸­ã‚†ãšã5æ­³ã§ã™ã€‚ä¼šè©±ã®ç›¸æ‰‹ã¯ä¿è‚²
å£«ã§ã™ã€‚"""
system_message_eval = """ã“ã“ã¾ã§ã§ä¼šè©±ã¯çµ‚äº†ã§ã™ã€‚ä¸Šè¨˜ã®ä¼šè©±ã®è©•ä¾¡çµæœã‚’è¡¨ç¤ºã—ã¦ãã ã•ã„ã€‚ã‚ãªãŸã¯ä¿è‚²å£«
ã®è¨€è‘‰ã«å¯¾ã—ã¦ä»¥ä¸‹ã®3ã¤ã®è¦³ç‚¹ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
* å®‰å¿ƒåº¦ : ** / 33.3ç‚¹
* æ©Ÿè»¢ : ** / 33.3ç‚¹
* é›·ã®å…‹æœåº¦ : ** / 33.3ç‚¹
ã¾ãŸã€ä¸Šè¨˜ã®è©•ä¾¡ã®ä»–ã«ã€ãã®å¾Œã®ã‚ãªãŸã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’æ›¸ãåŠ ãˆã¦ãã ã•ã„ã€‚ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã¯15å¹´å¾Œã®ã‚†ãšãã®è¦–ç‚¹
ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å›ç­”ã§è¨€åŠã•ã‚ŒãŸã“ã¨ã‚’äº¤ãˆã¦ã€ç‚¹æ•°ã«å¿œã˜ã¦ã‚ˆã„æ€ã„å‡ºã‹æ‚ªã„æ€ã„å‡ºã‹ãŒå¤‰ã‚ã‚‹ã€‚"""

initial_conversation = [
    {"role": "user", "content": "ï¼ˆä¿è‚²å£«ï¼‰ãŠã¯ã‚ˆã†ã€ã‚†ãšãã¡ã‚ƒã‚“ï¼ä»Šæ—¥ã¯ã¡ã‚‡ã£ã¨é›·ãŒé³´ã£ã¦ã‚‹ã‘ã©ã€å¤§ä¸ˆå¤«ã‹ãªï¼Ÿ"},
    {"role": "assistant", "content": "ï¼ˆã‚†ãšãï¼‰ã†ã…â€¦ã“ã‚ã„ã‚ˆã€œğŸ’¦"},
    {"role": "user", "content": "ï¼ˆä¿è‚²å£«ï¼‰ã©ã†ã—ã¦æ€–ã„ã®ã‹ãªï¼Ÿæ•™ãˆã¦ãã‚Œã‚‹ï¼Ÿ"},
    {"role": "assistant", "content": "ï¼ˆã‚†ãšãï¼‰ã ã£ã¦ã€ã‚´ãƒ­ã‚´ãƒ­è¨€ã£ã¦ã¦æ€’ã£ã¦ã‚‹ã¿ãŸã„ãªã‚“ã ã‚‚ã‚“ï¼"},
]

st.title("ã‚¸ã‚§ãƒãƒªãƒƒã‚¯ãŠã—ã‚ƒã¹ã‚Šã‚­ãƒ³ã‚°")

st.markdown("é›·ã§æ€–ãŒã£ã¦ã„ã‚‹ã‚†ãšãã¡ã‚ƒã‚“ã«å®‰å¿ƒã§ãã‚‹è¨€è‘‰ã‚’ã‹ã‘ã¦ã‚ã’ã‚ˆã†ã€‚")

if "log" not in st.session_state:
    st.session_state["log"] = [
        {"role": "system", "content": system_message_init}] + initial_conversation

for post in st.session_state["log"]:
    if post["role"] != "system":
        with st.chat_message(post["role"]):
            st.write(post["content"])

message = st.chat_input("ã‚ãªãŸã®è¨€è‘‰ã§ã€ã‚†ãšãã¡ã‚ƒã‚“ã‚’å®‰å¿ƒã•ã›ã¦ã‚ã’ã‚ˆã†ã€‚")

if message:
    st.session_state["log"].append({"role": "user", "content": message})
    st.session_state["log"].append(
        {"role": "system", "content": system_message_eval})
    with st.chat_message("user"):
        st.write(message)
    try:
        completion = client.chat.completions.create(
            messages=st.session_state["log"],
            max_tokens=500,

        )
        reply = completion.choices[0].message["content"]
        st.session_state["log"].append({"role": "assistant", "content": reply})
        with st.chat_message("assistant"):
            st.write(reply)

    except HfHubHTTPError:
        st.warning("ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
